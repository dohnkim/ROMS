{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 태풍 솔릭(Soulik) 모의를 위한<br/>GFS 자료로 ROMS 표층경계장(S.B.C.) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Dong-Hoon Kim (http://www.dhkim.info)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "from pygrib import open as grib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 기본 정보 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Info:  [96.3, 192.5] [3.2, 63.6]\n"
     ]
    }
   ],
   "source": [
    "expname = 'Soulik'; version = 'v4'\n",
    "\n",
    "tleadmax = 240\n",
    "dhour = 3\n",
    "\n",
    "date_beg = datetime(2018,8,21,0)\n",
    "date_end = datetime(2018,8,25,0)\n",
    "\n",
    "# ROMS 격자 정보 가져오기\n",
    "roms_grid_fname = '../Grid/'+expname+'_grd_'+version+'.nc'\n",
    "extraHoriz  = 2.0 # in degrees. use 2 times of delta X or delta Y.\n",
    "if not os.path.isfile(roms_grid_fname):\n",
    "    print(\"==>Error: not found - %s\"%roms_grid_fname)\n",
    "else:\n",
    "    with Dataset(roms_grid_fname) as roms_grid:\n",
    "        minmaxLonR = [round(roms_grid['lon_vert'][:].min()-extraHoriz,1), # west\n",
    "                      round(roms_grid['lon_vert'][:].max()+extraHoriz,1)] # east\n",
    "        minmaxLatR = [round(roms_grid['lat_vert'][:].min()-extraHoriz,1), # south\n",
    "                      round(roms_grid['lat_vert'][:].max()+extraHoriz,1)] # north\n",
    "        print('==>Info: ', minmaxLonR, minmaxLatR)\n",
    "region = {'lat1':minmaxLatR[0],'lat2':minmaxLatR[1],'lon1':minmaxLonR[0],'lon2':minmaxLonR[1]}\n",
    "# region = {'lat1':19,'lat2':54,'lon1':116,'lon2':161} # south, north, west, east\n",
    "# region = {'lat1':20,'lat2':50,'lon1':100,'lon2':154} # for LJH's grid\n",
    "\n",
    "# Grib Fields: {'shortName': [typeOfLevel, level, stepType]}\n",
    "fldGFS = {'dswrf':['surface',0,'avg'],              # Downward_Short-Wave_Radiation_Flux_surface_6_Hour_Average\n",
    "          'uswrf':['surface',0,'avg'],              # Upward_Short-Wave_Radiation_Flux_surface_6_Hour_Average\n",
    "          'dlwrf':['surface',0,'avg'],              # Downward_Long-Wave_Radp_Flux_surface_6_Hour_Average\n",
    "          'ulwrf':['surface',0,'avg'],              # Upward_Long-Wave_Radp_Flux_surface_6_Hour_Average\n",
    "          'lhtfl':['surface',0,'avg'],              # Latent_heat_net_flux_surface_6_Hour_Average\n",
    "          'shtfl':['surface',0,'avg'],              # Sensible_heat_net_flux_surface_6_Hour_Average\n",
    "          '2r'   :['heightAboveGround',2,'instant'],# 2 metre relative humidity\n",
    "          'tp'   :['surface',0,'accum'],            # Total Precipitation\n",
    "          'prate':['surface',0,'avg'],              # Precipitation_rate_surface_6_Hour_Average\n",
    "          'pevpr':['surface',0,'instant'],          # Potential evaporation rate\n",
    "          #'al'   :['surface',0,'avg'],              # Albedo\n",
    "          #'sde'  :['surface',0,'instant'],          # Snow depth\n",
    "          #'tcc'  :['unknown',0,'instant'],          # Total Cloud Cover\n",
    "          #'sp'   :['surface',0,'instant'],          # Surface Air Pressure\n",
    "          'prmsl':['meanSea',0,'instant'],          # Pressure_reduced_to_MSL_msl\n",
    "          '10u'  :['heightAboveGround',10,'instant'], # u-component_of_wind_height_above_ground (10 metre)\n",
    "          '10v'  :['heightAboveGround',10,'instant'], # v-component_of_wind_height_above_ground (10 metre)\n",
    "          't'    :['surface',0,'instant'],          # Surface Air Temperature\n",
    "          '2t'   :['heightAboveGround',2,'instant'],# 2 metre temperature\n",
    "          'lsm'  :['surface',0,'instant'],          # Land-sea mask (0-1)\n",
    "          'landn':['surface',0,'instant']           # Land-sea coverage (nearest neighbor) [land=1,sea=0]\n",
    "          }\n",
    "# the information of attributes { 'netcdf attr name': 'grib attr name'}\n",
    "attrGrib = {'long_name':'name','units':'units','step_type':'stepType',\n",
    "            'cf_name':'cfName','cf_var_name':'cfVarName'}\n",
    "\n",
    "fldROMS = ('Tair', 'Pair', 'Qair', 'Uwind', 'Vwind', 'swrad', 'lwrad_down', 'rain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GFS's grib2 자료 읽기\n",
    "\n",
    "### 1-1. GFS's grib2 자료를 읽는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGFS( version,tdate,tau_list,region ):\n",
    "    \"\"\"\n",
    "    version: GFSncdc, GFSncep, GFSgdas\n",
    "    region: {'lat1':-90,'lat2':90,'lon1':0,'lon2':360}\n",
    "    \"\"\"\n",
    "    #sixHourly = tdate.hour - tdate.hour%6\n",
    "    #release_date = tdate.replace(hour=sixHourly,minute=0,second=0,microsecond=0)\n",
    "    \n",
    "    if   version == 'GFSncdc': # '201906/20190601/gfs_4_20190601_1200_0240.grb2'\n",
    "        header = 'GFS/{}/gfs_4_{}_%3.3i.grb2'.format(\n",
    "                 tdate.strftime('%Y%m/%Y%m%d'),tdate.strftime('%Y%m%d_%H%M'))\n",
    "    elif version == 'GFSncep': # 'gfs.2019060112/gfs.t12z.pgrb2.0p25.f0240'\n",
    "        header = 'GFS/gfs.{}/gfs.{}.pgrb2.0p25.f%3.3i'.format(\n",
    "                 tdate.strftime('%Y%m%d%H'),tdate.strftime('t%Hz'))\n",
    "    elif version == 'GFSgdas': # 'gdas.20190601/gdas.t12z.pgrb2.0p25.f009'\n",
    "        header = 'GFS/gdas.{}/gdas.{}.pgrb2.0p25.f%3.3i'.format(\n",
    "                 tdate.strftime('%Y%m%d'),tdate.strftime('t%Hz'))\n",
    "    else: print('==>Error: incorrect version (%s)'%version); return pd.DataFrame()\n",
    "    \n",
    "    # create a new GFSraw\n",
    "    try:\n",
    "        with grib(header%(tau_list[0])) as grbs:\n",
    "            time = pd.date_range(tdate,tdate+timedelta(hours=tau_list[-1]),freq='%dH'%dhour)\n",
    "            \n",
    "            # get the latitude and longitude informations\n",
    "            k = 'landn'; v = fldGFS[k]\n",
    "            sforc = grbs.select(shortName=k,typeOfLevel=v[0],level=v[1])\n",
    "            gdata = sforc[0].data(lat1=region['lat1'],lat2=region['lat2'],\n",
    "                                  lon1=region['lon1'],lon2=region['lon2'])\n",
    "            \n",
    "            GFSraw = xr.Dataset() # create a new GFSraw\n",
    "            \n",
    "            GFSraw['time'] = time\n",
    "            GFSraw['lat2d'] = (('lat','lon'),gdata[1])\n",
    "            GFSraw['lon2d'] = (('lat','lon'),gdata[2])\n",
    "            \n",
    "            ntim,nlat,nlon = GFSraw.dims['time'],GFSraw.dims['lat'],GFSraw.dims['lon']\n",
    "            \n",
    "            # create empty forcing values\n",
    "            for k in fldGFS.keys(): \n",
    "                GFSraw[k] = (('time','lat','lon'), np.ones((ntim,nlat,nlon))*np.nan)\n",
    "                \n",
    "            GFSraw.attrs['history'] = grbs.name\n",
    "    except Exception as ex:\n",
    "        print('==>Error: %s. GFS data at %s.'%(ex,header%(tau_list[0]))); return GFSraw\n",
    "    \n",
    "    for tnum, tlead in enumerate(tau_list):\n",
    "        if tlead > tleadmax:\n",
    "            print('==>Error: exceeded max tlead (%i/%i)'%(tlead,tleadmax)); break\n",
    "        if tlead%dhour != 0:\n",
    "            print('==>Error: tlead must be every %i hourly but %i'%(dhour,tlead//dhour)); break\n",
    "            \n",
    "        tau_date = tdate+timedelta(hours=tlead)\n",
    "  \n",
    "        GFSlocal = header%tlead\n",
    "        if os.path.isfile(GFSlocal):\n",
    "            print('==>Info(%s): reading %s for SBC'%(version,GFSlocal))\n",
    "        else:\n",
    "            print('==>Error(%s): not found %s for SBC'%(version,GFSlocal)); break\n",
    "  \n",
    "        try:\n",
    "            with grib(GFSlocal) as grbs:\n",
    "                gdata = {}; ginfo = {}\n",
    "                for k,v in fldGFS.items():\n",
    "                    # Note) no flux or rate at fcst time 0 (tlead == 0 and stepType == 'avg|accum')\n",
    "                    if tlead == 0 and (v[2] == 'avg' or v[2] == 'accum' or k == 'pevpr'):\n",
    "                        GFSraw[k][tnum,:,:] = np.zeros((nlat,nlon)) # no flux or rate at fcst time 0\n",
    "                    else:\n",
    "                        try: \n",
    "                            sforc = grbs.select(shortName=k,typeOfLevel=v[0],level=v[1])\n",
    "                            if len(sforc) == 1: # sforc[0].data()[0]: 0:data,1:lat,2:lon\n",
    "                                sforc = sforc[0]; ginfo[k] = {}\n",
    "                                for nk,nv in attrGrib.items(): ginfo[k][nk] = sforc[nv]\n",
    "                                GFSraw[k][tnum,:,:] = sforc.data(lat1=region['lat1'],lat2=region['lat2'],\n",
    "                                                                 lon1=region['lon1'],lon2=region['lon2'])[0]\n",
    "                            else: \n",
    "                                print('==>Error(%s): '%k,sforc); raise StopIteration\n",
    "                            \n",
    "                            # insert attributes if none\n",
    "                            if 'units' not in GFSraw[k].attrs.keys():\n",
    "                                for ak,av in attrGrib.items():\n",
    "                                    GFSraw[k].attrs[ak] = sforc[av]\n",
    "                        except ValueError as e: \n",
    "                            print('==>Error(%s): '%k, e); raise StopIteration\n",
    "                            \n",
    "        except Exception as ex:\n",
    "            print('==>Error: %s. GFS data at %s.'%(ex,GFSlocal)); break\n",
    "            \n",
    "    return GFSraw # var[name].loc[tau][y,x] as pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 자료 변환 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields = ('Shortwave' ,'Net_Heat', 'U10', 'V10', 'Precipitation', 'Evaporation', 'SLP')\n",
    "# merra2 = ('T2M', 'SLP', 'QV2M', 'U10M', 'V10M', 'SWGDN', 'LWGAB', 'ALBEDO', 'CLDTOT', 'PRECLS', 'PRECSN'\n",
    "# fields = ('Tair', 'Pair', 'Qair', 'Uwind', 'Vwind', 'swrad', 'lwrad_down', 'albedo', 'cloud', 'rain', 'snow')\n",
    "# fields = ('Tair', 'Pair', 'Qair', 'Uwind', 'Vwind', 'swrad', 'lwrad_down', 'rain')\n",
    "# fields = ('Shortwave' ,'Net_Heat', 'U10', 'V10', 'Precipitation', 'Evaporation', 'SLP')\n",
    "\n",
    "def transGFS( GFSraw, time_units='seconds since 2000-01-01 00:00:00' ):\n",
    "    nlat = GFSraw.dims['lat']; nlon = GFSraw.dims['lon']\n",
    "    \n",
    "    GFStrn = xr.Dataset() # create a new GFStrn\n",
    "    # coordinates\n",
    "    GFStrn['time'] = GFSraw['time']\n",
    "    GFStrn['lat']  = GFSraw['lat2d'][::-1,int(nlon/2)] # middle latitude\n",
    "    GFStrn['lon']  = GFSraw['lon2d'][int(nlat/2),:]    # middle longitude\n",
    "    \n",
    "    for v in fldROMS:\n",
    "        if v == 'Tair': # K -> C\n",
    "            GFStrn[v] = (('tair_time','lat','lon'), GFSraw['2t'][:,::-1,:] - 273.15)\n",
    "            GFStrn[v].attrs = GFSraw['2t'].attrs\n",
    "            GFStrn[v].attrs['units'] = 'Celsius'; GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            GFStrn['tair_time'] = GFSraw['time']\n",
    "        elif v == 'Pair': # (1 mb = 100 Pa)\n",
    "            GFStrn[v] = (('pair_time','lat','lon'), GFSraw['prmsl'][:,::-1,:] / 100.)\n",
    "            GFStrn[v].attrs = GFSraw['prmsl'].attrs\n",
    "            GFStrn[v].attrs['units'] = 'milibar'; GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            #v = 'Pair2' # change var name\n",
    "            #GFStrn[v] = (('pair_time','lat','lon'), GFSraw['sp'][:,::-1,:] / 100.)\n",
    "            #GFStrn[v].attrs = GFSraw['sp'].attrs; #GFStrn[v].attrs['units'] = 'milibar'\n",
    "            GFStrn['pair_time'] = GFSraw['time']\n",
    "        elif v == 'Qair': # %\n",
    "            GFStrn[v] = (('qair_time','lat','lon'), GFSraw['2r'][:,::-1,:])\n",
    "            GFStrn[v].attrs = GFSraw['2r'].attrs # no needed with full copy\n",
    "            GFStrn[v].attrs['units'] = 'percentage'; GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            GFStrn['qair_time'] = GFSraw['time']\n",
    "        elif v == 'Uwind':\n",
    "            GFStrn[v] = (('wind_time','lat','lon'), GFSraw['10u'][:,::-1,:])\n",
    "            GFStrn[v].attrs = GFSraw['10u'].attrs # no needed with full copy\n",
    "            GFStrn[v].attrs['units'] = 'meter second-1'; GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            GFStrn['wind_time'] = GFSraw['time']\n",
    "        elif v == 'Vwind':\n",
    "            GFStrn[v] = (('wind_time','lat','lon'), GFSraw['10v'][:,::-1,:])\n",
    "            GFStrn[v].attrs = GFSraw['10v'].attrs # no needed with full copy\n",
    "            GFStrn[v].attrs['units'] = 'meter second-1'; GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            #GFStrn['wind_time'] = GFSraw['time']\n",
    "        elif v == 'swrad': # Note) upward is negative.  Shorwave = dswsfc - uswsfc\n",
    "            GFStrn[v] = (('srf_time','lat','lon'), (GFSraw['dswrf'][:,::-1,:] - GFSraw['uswrf'][:,::-1,:]) )\n",
    "            if GFSraw['dswrf'].attrs['step_type'] == 'accum': GFStrn[v] /= (dhour*3600)\n",
    "            GFStrn[v].attrs = GFSraw['dswrf'].attrs\n",
    "            GFStrn[v].attrs['long_name'] = 'Net short-wave radiation flux'\n",
    "            GFStrn[v].attrs['units'] = 'watt meter-2'\n",
    "            GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            GFStrn[v][0,:,:] = GFStrn[v][1,:,:] # flux[0] = flux[1]\n",
    "            GFStrn['srf_time'] = GFSraw['time']\n",
    "        elif v == 'lwrad_down':\n",
    "            GFStrn[v] = (('lrf_time','lat','lon'), GFSraw['dlwrf'][:,::-1,:])\n",
    "            if GFSraw['dlwrf'].attrs['step_type'] == 'accum': GFStrn[v] /= (dhour*3600)\n",
    "            GFStrn[v].attrs = GFSraw['dlwrf'].attrs\n",
    "            GFStrn[v].attrs['units'] = 'watt meter-2'\n",
    "            GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            GFStrn[v][0,:,:] = GFStrn[v][1,:,:] # flux[0] = flux[1]\n",
    "            GFStrn['lrf_time'] = GFSraw['time']\n",
    "        elif v == 'rain':\n",
    "            #Rho_w = 1000. # water density (kg/m^3)\n",
    "            #GFStrn[v] = (('rain_time','lat','lon'), GFSraw['tp'][:,::-1,:] * Rho_w)\n",
    "            #if GFSraw['tp'].attrs['step_type'] == 'accum': GFStrn[v] /= (dhour*3600)\n",
    "            #GFStrn[v].attrs = GFSraw['tp'].attrs\n",
    "            GFStrn[v] = (('rain_time','lat','lon'), GFSraw['prate'][:,::-1,:])\n",
    "            if GFSraw['prate'].attrs['step_type'] == 'accum': GFStrn[v] /= (dhour*3600)\n",
    "            GFStrn[v].attrs = GFSraw['prate'].attrs\n",
    "            GFStrn[v].attrs['long_name'] = 'Rain fall rate'\n",
    "            GFStrn[v].attrs['units'] = 'kilogram meter-2 second-1'\n",
    "            GFStrn[v].attrs['coordinates'] = 'lon lat'\n",
    "            GFStrn[v][0,:,:] = GFStrn[v][1,:,:] # flux[0] = flux[1]\n",
    "            GFStrn['rain_time'] = GFSraw['time']\n",
    "        else: print('==>Error: incorrect field value - %s'%v); return GFStrn\n",
    "        \n",
    "    GFStrn['time'].attrs['long_name'] = 'time'\n",
    "    GFStrn['lat'].attrs = {'long_name':'latitude','units':'degrees_north'}\n",
    "    GFStrn['lon'].attrs = {'long_name':'longitude','units':'degrees_east'}\n",
    "        \n",
    "    # Global attributes\n",
    "    GFStrn.attrs['Author'] = 'Dong-Hoon Kim (www.dhkim.info)'\n",
    "    GFStrn.attrs['Comment'] = ''\n",
    "    GFStrn.attrs['Title'] = 'Surface forcing from GFS dataset for ROMS'\n",
    "    GFStrn.attrs['Created'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    GFStrn.attrs['History'] = GFSraw.attrs['history']\n",
    "    \n",
    "    return GFStrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. S.B.C. 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_000.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_003.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_006.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_009.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_012.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_015.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_018.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_021.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_024.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_027.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_030.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_033.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_036.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_039.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_042.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_045.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_048.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_051.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_054.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_057.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_060.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_063.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_066.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_069.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_072.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_075.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_078.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_081.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_084.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_087.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_090.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_093.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_096.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_099.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_102.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_105.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_108.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_111.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_114.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_117.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_120.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_123.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_126.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_129.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_132.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_135.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_138.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_141.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_144.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_147.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_150.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_153.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_156.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_159.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_162.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_165.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_168.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_171.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_174.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_177.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_180.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_183.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_186.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_189.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_192.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_195.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_198.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_201.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_204.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_207.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_210.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_213.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_216.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_219.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_222.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_225.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_228.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_231.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_234.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_237.grb2 for SBC\n",
      "==>Info(GFSncdc): reading GFS/201808/20180821/gfs_4_20180821_0000_240.grb2 for SBC\n",
      "\n",
      "==>Info: creating roms_gfs_0p25_sbc_Soulik.nc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GFSraw = getGFS( 'GFSncep', datetime(2019,6,1,12),list(range(0,4,3)),region)\n",
    "GFSraw = getGFS( 'GFSncdc', date_beg,list(range(0,241,3)),region)\n",
    "# ds.to_netcdf('test.nc','w',format='NETCDF3_CLASSIC',unlimited_dims=['time',])\n",
    "# _=plt.imshow(ds['2t'][0,:,:]) # var[name][t,y,x]\n",
    "\n",
    "GFStrn = transGFS(GFSraw)\n",
    "\n",
    "# save to netcdf format\n",
    "roms_gfs = 'roms_gfs_0p25_sbc_%s.nc'%expname\n",
    "time_units = {}\n",
    "for tn in ('time','tair_time','pair_time','qair_time','wind_time','srf_time','lrf_time','rain_time'):\n",
    "    time_units[tn] = {'units': 'days since 2000-01-01 00:00:00'}\n",
    "    #time_units[tn] = {'units': 'seconds since 2000-01-01 00:00:00'}\n",
    "GFStrn.to_netcdf(roms_gfs,'w',format='NETCDF3_CLASSIC',encoding=time_units,unlimited_dims=['time',])\n",
    "print('\\n==>Info: creating %s\\n'%roms_gfs)\n",
    "# _=plt.imshow(dc['Pair'][0,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROMS",
   "language": "python",
   "name": "roms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
